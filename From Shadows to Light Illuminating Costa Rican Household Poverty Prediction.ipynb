{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4412db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimensions of the dataframe\n",
    "print(f\"The dataset contains {df.shape[0]} rows and {df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fec8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an overview of the dataframe\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "missing_cols = df.columns[df.isnull().sum() > 0]\n",
    "print(f\"Columns with missing values: {missing_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with backward fill and forward fill methods\n",
    "df.fillna(method='bfill',inplace=True)\n",
    "df.fillna(method='ffill',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that there are no more missing values\n",
    "assert df.isnull().sum().sum() == 0, \"There are still missing values in the dataframe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a211f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of the columns\n",
    "numeric_columns = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_columns = set(df.columns).difference(set(numeric_columns))\n",
    "print(f\"Numeric columns: {numeric_columns}\")\n",
    "print(f\"Categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e35c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'edjefe' and 'edjefa' columns to numeric\n",
    "df['edjefe'] = df['edjefe'].replace({'no': 0, 'yes':1}).astype(float)\n",
    "df['edjefa'] = df['edjefa'].replace({'no': 0, 'yes':1}).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9213704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate the 'dependency' column\n",
    "df['dependency'] = np.sqrt(df['SQBdependency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "col_drops = ['Id','idhogar']\n",
    "df.drop(col_drops,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric columns\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8268ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a94405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the target variable to understand its distribution\n",
    "sns.countplot(df['Target'])\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446af4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation between numerical features\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26610e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "\n",
    "# Ensure we avoid division by zero by replacing zeros in denominators with a small constant.\n",
    "eps = 1e-8\n",
    "\n",
    "# Calculate ratios and per-person features\n",
    "df['rent_per_adult'] = df['v2a1'] / (df['hogar_adul'] + eps)\n",
    "df['rent_per_person'] = df['v2a1'] / (df['hhsize'] + eps)\n",
    "df['overcrowding_room_and_bedroom'] = (df['hacdor'] + df['hacapo']) / 2\n",
    "df['no_appliances'] = df['refrig'] + df['computer'] + df['television']\n",
    "df['r4h1_percent_in_male'] = df['r4h1'] / (df['r4h3'] + eps)\n",
    "df['r4m1_percent_in_female'] = df['r4m1'] / (df['r4m3'] + eps)\n",
    "df['r4h1_percent_in_total'] = df['r4h1'] / (df['hhsize'] + eps)\n",
    "df['r4m1_percent_in_total'] = df['r4m1'] / (df['hhsize'] + eps)\n",
    "df['r4t1_percent_in_total'] = df['r4t1'] / (df['hhsize'] + eps)\n",
    "\n",
    "# Calculate new features by subtracting & adding related features\n",
    "df['adult'] = df['hogar_adul'] - df['hogar_mayor']\n",
    "df['dependency_count'] = df['hogar_nin'] + df['hogar_mayor']\n",
    "df['dependency'] = df['dependency_count'] / (df['adult'] + eps)\n",
    "df['child_percent'] = df['hogar_nin'] / (df['hogar_total'] + eps)\n",
    "df['elder_percent'] = df['hogar_mayor'] / (df['hogar_total'] + eps)\n",
    "df['adult_percent'] = df['hogar_adul'] / (df['hogar_total'] + eps)\n",
    "\n",
    "# Calculate features by comparing different household attributes\n",
    "df['rent_per_bedroom'] = df['v2a1'] / (df['bedrooms'] + eps)\n",
    "df['adults_per_bedroom'] = df['adult'] / (df['bedrooms'] + eps)\n",
    "df['child_per_bedroom'] = df['hogar_nin'] / (df['bedrooms'] + eps)\n",
    "df['male_per_bedroom'] = df['r4h3'] / (df['bedrooms'] + eps)\n",
    "df['female_per_bedroom'] = df['r4m3'] / (df['bedrooms'] + eps)\n",
    "df['bedrooms_per_person_household'] = df['hhsize'] / (df['bedrooms'] + eps)\n",
    "df['tablet_per_person_household'] = df['v18q1'] / (df['hhsize'] + eps)\n",
    "df['phone_per_person_household'] = df['qmobilephone'] / (df['hhsize'] + eps)\n",
    "df['age_12_19'] = df['hogar_nin'] - df['r4t1']\n",
    "df['rent_per_room'] = df['v2a1'] / (df['rooms'] + eps)\n",
    "df['bedroom_per_room'] = df['bedrooms'] / (df['rooms'] + eps)\n",
    "df['elder_per_room'] = df['hogar_mayor'] / (df['rooms'] + eps)\n",
    "df['adults_per_room'] = df['adult'] / (df['rooms'] + eps)\n",
    "df['child_per_room'] = df['hogar_nin'] / (df['rooms'] + eps)\n",
    "df['male_per_room'] = df['r4h3'] / (df['rooms'] + eps)\n",
    "df['female_per_room'] = df['r4m3'] / (df['rooms'] + eps)\n",
    "df['room_per_person_household'] = df['hhsize'] / (df['rooms'] + eps)\n",
    "\n",
    "# Calculate ratios for years of schooling and schooling relative to age\n",
    "df['escolari_age'] = df['escolari'] / (df['age'] + eps)\n",
    "df['rez_esc_escolari'] = df['rez_esc'] / (df['escolari'] + eps)\n",
    "df['rez_esc_r4t1'] = df['rez_esc'] / (df['r4t1'] + eps)\n",
    "df['rez_esc_r4t2'] = df['rez_esc'] / (df['r4t2'] + eps)\n",
    "df['rez_esc_r4t3'] = df['rez_esc'] / (df['r4t3'] + eps)\n",
    "df['rez_esc_age'] = df['rez_esc'] / (df['age'] + eps)\n",
    "\n",
    "# Remove ID variables\n",
    "# df.drop(columns=['Id', 'idhogar'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_1 = df.drop('Target',axis=1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "x_1.shape\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "y = df['Target']\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "\n",
    "\n",
    "# ## Optimizing Xgboost\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def xgb_cv(n_estimators, max_depth, gamma, subsample, data, targets):\n",
    "    estimator = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth = max_depth,\n",
    "        gamma = gamma,\n",
    "        # min_child_weight=min_child_weight,\n",
    "        subsample = subsample,\n",
    "        random_state = 2,\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, targets\n",
    "                          , cv=5)\n",
    "    return cval.mean()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def optimize_xgb(data, targets):\n",
    "    def xgb_crossval(n_estimators, max_depth, gamma, subsample):\n",
    "        return xgb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth = int(max_depth),\n",
    "            gamma = gamma,\n",
    "            # min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            targets=targets,\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=xgb_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\": (100, 500),\n",
    "            \"max_depth\": (6,15),\n",
    "            \"gamma\": (0,10),\n",
    "            # \"min_child_weight\": (0,10),\n",
    "            \"subsample\": (0.8,1.0)\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=25, init_points=10)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"--- Optimizing XGBoost ---\")\n",
    "optimize_xgb(x_1, y)\n",
    "\n",
    "\n",
    "# ## Optimizing Catboost\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def cb_cv(n_estimators, depth,data, targets):\n",
    "    estimator = CatBoostClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "#         learning_rate=learning_rate,\n",
    "        depth=depth,\n",
    "        random_state = 2,\n",
    "        verbose = 0,\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, targets,\n",
    "                            cv=5)\n",
    "    return cval.mean()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def optimize_cb(data, targets):\n",
    "    def cb_crossval(n_estimators, depth):\n",
    "        return cb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "#             learning_rate = learning_rate,\n",
    "            depth = int(depth),\n",
    "            data=data,\n",
    "            targets=targets,\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=cb_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\": (200, 600),\n",
    "#             \"learning_rate\": (0.01,10),\n",
    "            \"depth\": (4,16),\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=25, init_points=20)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(\"--- Optimizing Catboost ---\")\n",
    "optimize_cb(x_1, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(n_estimators, num_leaves, min_child_samples, subsample, data, targets):\n",
    "    estimator = LGBMClassifier(\n",
    "        n_estimators=int(n_estimators),\n",
    "        num_leaves=int(num_leaves),\n",
    "        min_child_samples=int(min_child_samples),\n",
    "        subsample=subsample,\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, targets, cv=5, scoring='accuracy')\n",
    "    return cval.mean()\n",
    "\n",
    "def optimize_lgb(data, targets):\n",
    "    def lgb_crossval(n_estimators, num_leaves, min_child_samples, subsample):\n",
    "        return lgb_cv(\n",
    "            n_estimators=n_estimators,\n",
    "            num_leaves=num_leaves,\n",
    "            min_child_samples=min_child_samples,\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            targets=targets,\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=lgb_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\": (100, 500),\n",
    "            \"num_leaves\": (30, 80),\n",
    "            \"min_child_samples\": (5, 30),\n",
    "            \"subsample\": (0.6, 1.0)\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=25, init_points=20)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "\n",
    "print(\"--- Optimizing LightGBM ---\")\n",
    "optimize_lgb(x_1, y)\n",
    "\n",
    "# Model Fitting\n",
    "Xg = XGBClassifier()\n",
    "Lgbm = LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, num_leaves=200)\n",
    "Cataboost = CatBoostClassifier(depth=9, n_estimators=514)\n",
    "\n",
    "estimators = [('Cataboost', Cataboost), ('Xg', Xg), ('Lgbm', Lgbm)]\n",
    "clf = StackingClassifier(estimators=estimators)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
